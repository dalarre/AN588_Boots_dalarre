---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


##Homework 05

#[1] Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}

library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
names(d)
## This loads the data

```

```{r}
library(lmodel2) ## Load the Model II regression package

hr <- log(d$HomeRange_km2)
bmfm <- log(d$Body_mass_female_mean)

f <- cbind(d, hr, bmfm)

m <- lmodel2(hr ~ bmfm, data = f, range.y = "interval", range.x = "relative", 
    nperm = 1000)
m

b1 <- m$regression.results$Slope[1]
b1 ##Slope

b0 <- m$regression.results$Intercept[1]
b0 ##Intercept

```

#[2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

How does the latter compare to the 95% CI estimated from your entire dataset?

```{r}
s1 <- NULL
s2 <- NULL
for (i in 1:1000) {
    s1[[i]] <- sample(f$hr, size = 100, replace = TRUE)
    s2[[i]] <- sample(f$bmfm, size = 100, replace = TRUE)
}
## First, I sample 1000 times from each variable, with a sample size of 100


mm <- NULL
for (i in 1:1000) {
  mm[[i]] <- lmodel2(s1[[i]]~s2[[i]],data = f, range.y = "interval", range.x = "relative")
}
mm[[1]]
mm[[1000]]
## Then I run a for loop for doing the model 2 regression of each sample. I get the warning that "No permutation test will be performed" on each regression because if I add a permutation number the loop takes forever to run.

mmi <- NULL
for (i in 1:1000) {
  mmi[[i]] <- lm(s1[[i]]~s2[[i]])
}
mmi[[1]]
mmi[[1000]]
## Here I do a test to see if there is a notable difference between using linear model 1 or 2, and the results are pretty much the same in both of them.

```



